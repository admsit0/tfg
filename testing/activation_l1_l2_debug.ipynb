{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba679e1",
   "metadata": {},
   "source": [
    "# Depuración de activaciones para L1 / L2\n",
    "Este notebook ejecuta experimentos controlados (un paso de entrenamiento) para comparar cómo afectan L1 y L2 con pesos extremos a las activaciones ocultas y al número de estados únicos.\n",
    "Usará utilidades existentes en `src.analysis` para contar estados únicos (rounding + np.unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99366c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK, device= cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports y helpers\n",
    "import os, sys\n",
    "ROOT = os.path.abspath(os.path.join(os.getcwd()))\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.insert(0, ROOT)\n",
    "PARENT_ROOT = os.path.abspath(os.path.join(ROOT, '..'))\n",
    "if PARENT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PARENT_ROOT)\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.utils.seed import set_seed\n",
    "from src.models import build_model\n",
    "from src.regularizers.l1 import L1Regularizer\n",
    "from src.regularizers.l2 import L2Regularizer\n",
    "from src.datasets.fashion_mnist import build_fashion_mnist\n",
    "from src.analysis.analysis import count_unique_states_rounding\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def collect_hidden_activations(model, loader, max_samples=2000, device=torch.device('cpu')):\n",
    "    model.eval()\n",
    "    acts = []\n",
    "    with torch.no_grad():\n",
    "        seen = 0\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            # model may expect (N,1,28,28) for FashionMNIST; SimpleFFW flattens\n",
    "            if hasattr(model, 'get_hidden'):\n",
    "                h = model.get_hidden(xb)\n",
    "            else:\n",
    "                out = model(xb, return_features=True)\n",
    "                if isinstance(out, tuple):\n",
    "                    _, h = out\n",
    "                else:\n",
    "                    # fallback: take output as features\n",
    "                    h = out\n",
    "            h = h.detach().cpu().numpy()\n",
    "            acts.append(h)\n",
    "            seen += h.shape[0]\n",
    "            if seen >= max_samples:\n",
    "                break\n",
    "    if not acts:\n",
    "        return np.empty((0,0))\n",
    "    X = np.vstack(acts)[:max_samples]\n",
    "    return X\n",
    "\n",
    "def run_one(reg_type=None, weight=0.0, seed=42, hidden_dim=64, sample_limit=2000):\n",
    "    set_seed(seed)\n",
    "    # build small model for speed\n",
    "    m = build_model('simple_ffw', dataset='fashion_mnist', input_dim=28*28, hidden_dim=hidden_dim, num_classes=10, dropout=0.0)\n",
    "    m.to(device)\n",
    "\n",
    "    # prepare data (small subset)\n",
    "    data_dir = os.path.join(ROOT, 'data')\n",
    "    train_loader, test_loader = build_fashion_mnist(data_dir=data_dir, batch_size=128, train_split=1.0, subset_ratio=0.05, test_subset_ratio=0.05, seed=seed)\n",
    "    # pick a deterministic small batch for the single training step\n",
    "    xb, yb = next(iter(train_loader))\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "    # compute parameter norms before step\n",
    "    with torch.no_grad():\n",
    "        param_l1_before = sum(p.abs().sum().item() for p in m.parameters())\n",
    "        param_l2_before = sum((p**2).sum().item() for p in m.parameters())\n",
    "\n",
    "    opt = torch.optim.SGD(m.parameters(), lr=0.01)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # regularizer penalty\n",
    "    penalty = torch.tensor(0.0, dtype=torch.float32)\n",
    "    if reg_type == 'l1':\n",
    "        reg = L1Regularizer(weight=weight)\n",
    "        penalty = reg.penalty(m)\n",
    "    elif reg_type == 'l2':\n",
    "        reg = L2Regularizer(weight=weight)\n",
    "        penalty = reg.penalty(m)\n",
    "\n",
    "    # one forward/backward/step\n",
    "    m.train()\n",
    "    out = m(xb)\n",
    "    if isinstance(out, tuple):\n",
    "        out = out[0]\n",
    "    loss = loss_fn(out, yb)\n",
    "    total = loss + penalty.to(loss.device)\n",
    "    opt.zero_grad()\n",
    "    total.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # compute parameter norms after step\n",
    "    with torch.no_grad():\n",
    "        param_l1_after = sum(p.abs().sum().item() for p in m.parameters())\n",
    "        param_l2_after = sum((p**2).sum().item() for p in m.parameters())\n",
    "\n",
    "    # collect hidden activations from test set (or subset)\n",
    "    X = collect_hidden_activations(m, test_loader, max_samples=sample_limit, device=device)\n",
    "    if X.size == 0:\n",
    "        n_states = 0\n",
    "    else:\n",
    "        n_states, reps = count_unique_states_rounding(X, decimals=5, normalize_l2=True)\n",
    "\n",
    "    return {\n",
    "        'reg_type': reg_type or 'baseline',\n",
    "        'weight': weight,\n",
    "        'n_states': int(n_states),\n",
    "        'param_l1_before': float(param_l1_before),\n",
    "        'param_l2_before': float(param_l2_before),\n",
    "        'param_l1_after': float(param_l1_after),\n",
    "        'param_l2_after': float(param_l2_after),\n",
    "    }\n",
    "\n",
    "# quick smoke run to verify everything loads\n",
    "print('Imports OK, device=', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad7c7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline None 0.0\n",
      "Running l1 1.0 1.0\n",
      "Running l1 0.1 0.1\n",
      "Running l2 1.0 1.0\n",
      "Running l2 0.1 0.1\n",
      "\n",
      "   reg_type  weight  n_states  param_l1_before  param_l2_before  \\\n",
      "0  baseline     0.0       500       937.440515         24.72053   \n",
      "1       1.0     1.0       500       937.440515         24.72053   \n",
      "2       0.1     0.1       500       937.440515         24.72053   \n",
      "3       1.0     1.0       500       937.440515         24.72053   \n",
      "4       0.1     0.1       500       937.440515         24.72053   \n",
      "\n",
      "   param_l1_after  param_l2_after  \n",
      "0      937.417711        24.71788  \n",
      "1      937.417711        24.71788  \n",
      "2      937.417711        24.71788  \n",
      "3      937.417711        24.71788  \n",
      "4      937.417711        24.71788  \n"
     ]
    }
   ],
   "source": [
    "# Run experiments for selected configs\n",
    "configs = [\n",
    "    ('baseline', None, 0.0),\n",
    "    ('l1', 1.0, 1.0),\n",
    "    ('l1', 0.1, 0.1),\n",
    "    ('l2', 1.0, 1.0),\n",
    "    ('l2', 0.1, 0.1),\n",
    "]\n",
    "results = []\n",
    "for name, rtype, w in configs:\n",
    "    print('Running', name, rtype, w)\n",
    "    if rtype is None:\n",
    "        res = run_one(reg_type=None, weight=0.0, seed=1234, hidden_dim=64, sample_limit=1200)\n",
    "    else:\n",
    "        res = run_one(reg_type=rtype, weight=w, seed=1234, hidden_dim=64, sample_limit=1200)\n",
    "    results.append(res)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fae78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50e87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
